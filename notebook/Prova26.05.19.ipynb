{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/victorhugo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/victorhugo/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação das bibliotecas criadas para normalização dos dados\n",
    "from nlputils import lexical\n",
    "from nlputils import morphosyntax\n",
    "from nlputils import syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamada da bibioteca de preprocessamento\n",
    "lexical_normalizer = lexical.Preprocessing()\n",
    "morphosyntax_normalizer = morphosyntax.Preprocessing('../models/pt_core_news_sm-2.1.0')\n",
    "syntax_normalizer = syntax.Preprocessing('../models/pt_core_news_sm-2.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#definição do diretorio dos corpus e criacao de uma lista com os nomes de cada arquivo dentro do diretorio\n",
    "corpora_path = '../data/corpora/'\n",
    "files_corpora = os.listdir(corpora_path)\n",
    "files_corpora = [d for d in files_corpora if d not in '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n",
      "533\n"
     ]
    }
   ],
   "source": [
    "#criacao de um dicionario que ira armazenar cada corpus em uma chave\n",
    "sentences_dic = {}\n",
    "all_files = []\n",
    "for corpus in files_corpora:\n",
    "    files = [os.path.join(corpora_path + corpus, f) \\\n",
    "             for f in os.listdir(corpora_path + corpus) \\\n",
    "             if os.path.isfile(os.path.join(corpora_path + corpus, f))]\n",
    "    #cada corpus tera mais 4 chaves para armazenar informacoes de trabalho. Obs.: svo = sujeito, verbo, objeto\n",
    "    sentences_dic[corpus] = {'sentencas': [], 'tag': [], 'parse': [], 'svo': []}\n",
    "    \n",
    "    #adiciona todos os arquivos em uma unica lista independentemente do corpus\n",
    "    print(len(files))\n",
    "    all_files.extend(files)\n",
    "    \n",
    "    #para cada arquivo em um corpus sera extraido suas frases e armazenadas em cada linha de uma lista\n",
    "    # limitamos a 30 arquivos pois demora muito para compilar, para fazer o teste com todos é só remover a parte\n",
    "    # entre colchetes.\n",
    "    for file in files[:30]:\n",
    "        with open(file, 'r', encoding='utf-8') as text_file:\n",
    "            lines = text_file.readlines()\n",
    "            for line in lines:\n",
    "                if line != '\\n':\n",
    "                    #toda a sentenca sera escrita em letras minusculas\n",
    "                    #line = lexical_normalizer.lowercase(line) \n",
    "                    #tokeniza as sentencas\n",
    "                    sentences_line = lexical_normalizer.tokenize_sentences(line)\n",
    "                    for sentence in sentences_line:\n",
    "                        #print(sentence)\n",
    "                        #adiciona cada sentenca de uma linha no dicionario\n",
    "                        sentences_dic[corpus]['sentencas'].append(sentence)\n",
    "                        sentence = lexical_normalizer.remove_punctuation(sentence)\n",
    "                        #adiciona uma lista de cada palavra da sentenca taggeada composta de \n",
    "                        #(token, etiqueta_morfossintática)\n",
    "                        sentences_dic[corpus]['tag'].append(morphosyntax_normalizer.tag(sentence))\n",
    "                        #adiciona uma lista de cada palavra da sentenca composta de \n",
    "                        #(token, papel_sintático, head),\n",
    "                        sentences_dic[corpus]['parse'].append(syntax_normalizer.parse(sentence))\n",
    "                        #adiciona uma lista de cada sentenca composta por tuplas de (sujeito, verbo, objeto)\n",
    "                        sentences_dic[corpus]['svo'].append(syntax_normalizer.get_SVO(sentence))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['educacao', 'tecnologia'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizacao do Pandas para visualizao dos dados em forma de tabelas\n",
    "import pandas as pd\n",
    "\n",
    "#cracao de um dicionario que ira armazenar cada corpus em suas respectivas keys.\n",
    "dataframes_sentences = {}\n",
    "for key in sentences_dic.keys():\n",
    "    #os corpus armazenados aqui estara em formato de DataFrame onde cada key sera uma coluna da tabela\n",
    "    dataframes_sentences[key] = pd.DataFrame(sentences_dic[key], columns=['sentencas','tag','parse', 'svo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizamos dataframes para mostrar os dados dos córpus\n",
    "- como em nosso corpora temos os conteudos 'tecnologia' e 'educacao', separamos os dois para serem mostrados abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tag</th>\n",
       "      <th>parse</th>\n",
       "      <th>svo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aparelhos têm bateria de mais de 10 horas e po...</td>\n",
       "      <td>[(Aparelhos, PROPN), (têm, VERB), (bateria, NO...</td>\n",
       "      <td>[(Aparelhos, nsubj, têm), (têm, ROOT, têm), (b...</td>\n",
       "      <td>[(Aparelhos, têm, bateria), (Charge, são, caix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Com o popular design da fabricante, os aparelh...</td>\n",
       "      <td>[(Com, ADP), (o, DET), (popular, ADJ), (design...</td>\n",
       "      <td>[(Com, case, design), (o, det, design), (popul...</td>\n",
       "      <td>[(aparelhos, são, semelhantes), (no, são, seme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tanto a Charge 3 quanto a Xtreme estão à venda...</td>\n",
       "      <td>[(Tanto, ADV), (a, ADP), (Charge, PROPN), (3, ...</td>\n",
       "      <td>[(Tanto, cc, Charge), (a, det, Charge), (Charg...</td>\n",
       "      <td>[(Charge, estão, loja)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vale lembrar que já é possível encontrá-las ma...</td>\n",
       "      <td>[(Vale, VERB), (lembrar, VERB), (que, SCONJ), ...</td>\n",
       "      <td>[(Vale, ROOT, Vale), (lembrar, xcomp, Vale), (...</td>\n",
       "      <td>[(–, acompanham, da)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No entanto, as caixas de som têm tamanhos bast...</td>\n",
       "      <td>[(No, ADP), (entanto, NOUN), (as, DET), (caixa...</td>\n",
       "      <td>[(No, case, entanto), (entanto, obl, têm), (as...</td>\n",
       "      <td>[(caixas, têm, entanto), (Xtreme, precisa, 89)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  Aparelhos têm bateria de mais de 10 horas e po...   \n",
       "1  Com o popular design da fabricante, os aparelh...   \n",
       "2  Tanto a Charge 3 quanto a Xtreme estão à venda...   \n",
       "3  Vale lembrar que já é possível encontrá-las ma...   \n",
       "4  No entanto, as caixas de som têm tamanhos bast...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [(Aparelhos, PROPN), (têm, VERB), (bateria, NO...   \n",
       "1  [(Com, ADP), (o, DET), (popular, ADJ), (design...   \n",
       "2  [(Tanto, ADV), (a, ADP), (Charge, PROPN), (3, ...   \n",
       "3  [(Vale, VERB), (lembrar, VERB), (que, SCONJ), ...   \n",
       "4  [(No, ADP), (entanto, NOUN), (as, DET), (caixa...   \n",
       "\n",
       "                                               parse  \\\n",
       "0  [(Aparelhos, nsubj, têm), (têm, ROOT, têm), (b...   \n",
       "1  [(Com, case, design), (o, det, design), (popul...   \n",
       "2  [(Tanto, cc, Charge), (a, det, Charge), (Charg...   \n",
       "3  [(Vale, ROOT, Vale), (lembrar, xcomp, Vale), (...   \n",
       "4  [(No, case, entanto), (entanto, obl, têm), (as...   \n",
       "\n",
       "                                                 svo  \n",
       "0  [(Aparelhos, têm, bateria), (Charge, são, caix...  \n",
       "1  [(aparelhos, são, semelhantes), (no, são, seme...  \n",
       "2                            [(Charge, estão, loja)]  \n",
       "3                              [(–, acompanham, da)]  \n",
       "4    [(caixas, têm, entanto), (Xtreme, precisa, 89)]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_sentences['tecnologia'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tag</th>\n",
       "      <th>parse</th>\n",
       "      <th>svo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A esquerda: o louco, o criminoso e o drogado25...</td>\n",
       "      <td>[(A, DET), (esquerda, NOUN), (o, DET), (louco,...</td>\n",
       "      <td>[(A, det, esquerda), (esquerda, nsubj, crimino...</td>\n",
       "      <td>[(esquerda, é, criminoso), (tudo, é, subprodut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>), ou voltadas para a educação (orfanatórios, ...</td>\n",
       "      <td>[( , SPACE), (ou, PUNCT), (voltadas, NOUN), (p...</td>\n",
       "      <td>[( , , ou), (ou, cc, voltadas), (voltadas, ROO...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nada mais são senão que ‘espaços de opressão’ ...</td>\n",
       "      <td>[(nada, PRON), (mais, ADV), (são, VERB), (senã...</td>\n",
       "      <td>[(nada, fixed, que), (mais, advmod, nada), (sã...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seu objetivo maior não é a defesa da sociedade...</td>\n",
       "      <td>[(Seu, DET), (objetivo, NOUN), (maior, ADJ), (...</td>\n",
       "      <td>[(Seu, det, objetivo), (objetivo, nsubj, defes...</td>\n",
       "      <td>[(objetivo, é, defesa), (que, criar, mecanismo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Da mesma maneira, o existir do hospício serve ...</td>\n",
       "      <td>[(Da, NOUN), (mesma, DET), (maneira, NOUN), (o...</td>\n",
       "      <td>[(Da, ROOT, Da), (mesma, amod, maneira), (mane...</td>\n",
       "      <td>[(clínicos, excedam, psiquiátricos), (nos, Non...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  A esquerda: o louco, o criminoso e o drogado25...   \n",
       "1  ), ou voltadas para a educação (orfanatórios, ...   \n",
       "2  nada mais são senão que ‘espaços de opressão’ ...   \n",
       "3  Seu objetivo maior não é a defesa da sociedade...   \n",
       "4  Da mesma maneira, o existir do hospício serve ...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  [(A, DET), (esquerda, NOUN), (o, DET), (louco,...   \n",
       "1  [( , SPACE), (ou, PUNCT), (voltadas, NOUN), (p...   \n",
       "2  [(nada, PRON), (mais, ADV), (são, VERB), (senã...   \n",
       "3  [(Seu, DET), (objetivo, NOUN), (maior, ADJ), (...   \n",
       "4  [(Da, NOUN), (mesma, DET), (maneira, NOUN), (o...   \n",
       "\n",
       "                                               parse  \\\n",
       "0  [(A, det, esquerda), (esquerda, nsubj, crimino...   \n",
       "1  [( , , ou), (ou, cc, voltadas), (voltadas, ROO...   \n",
       "2  [(nada, fixed, que), (mais, advmod, nada), (sã...   \n",
       "3  [(Seu, det, objetivo), (objetivo, nsubj, defes...   \n",
       "4  [(Da, ROOT, Da), (mesma, amod, maneira), (mane...   \n",
       "\n",
       "                                                 svo  \n",
       "0  [(esquerda, é, criminoso), (tudo, é, subprodut...  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [(objetivo, é, defesa), (que, criar, mecanismo...  \n",
       "4  [(clínicos, excedam, psiquiátricos), (nos, Non...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_sentences['educacao'].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2:\n",
    "## Utilizando\t o\t corpora\t compilado\t para\t a\t Prova\t 1 e\t as\t rotinas definidas na questão\t anterior, realizar\t a\t extração\t de\t informações\t no\t formado\t de\t triplas:(Sujeito,\tVerbo,\tObjeto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a: Um\tdicionário\tPython\tdeve\tser\tcriado\tda\tseguinte\tforma: a. {“verbo lematizado1”: [(Sujeito1, Objeto1), (Sujeito2,None), ..., (Sujeiton, Objeton)], ..., “verbo lematizadok”: [(Sujeito1, Objeto1), (Sujeito2, Objeto2), ..., (Sujeitom, Objetom)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario contendo lista de verbos e para cada verbo uma lista de tuplas contendo (Sujeito, Objeto)\n",
    "lemma_verb = {}\n",
    "#lista de tuplas dos verbos que nao possuem sujeito no formato (verbo lematizado, verbo encontrado)\n",
    "no_obj_verb = []\n",
    "#para cada corpus\n",
    "for corpus in sentences_dic:\n",
    "    #pegaremos as sentencas em sentences_dic[corpus]['svo']\n",
    "    for sentence in sentences_dic[corpus]['svo']:\n",
    "        #pegaremos cada tripla na lista de triplas(sujeito, verbo, objeto) da sentenca\n",
    "        for svo in sentence:\n",
    "            #evitar pegar casos vazios\n",
    "            if svo[1] != None:\n",
    "                #recebe o verbo lematizado\n",
    "                verb = svo[1].lemma_\n",
    "                #verifica se o verbo ainda não foi adicionado no dicionario\n",
    "                if verb in lemma_verb.keys():\n",
    "                    #tupla com sujeito e objeto\n",
    "                    lemma_verb[verb].append((svo[0], svo[2]))\n",
    "                else:\n",
    "                    #cria a chave do verbo e adiciona a tupla com sujeito e objeto\n",
    "                    lemma_verb[verb] = []\n",
    "                    lemma_verb[verb].append((svo[0], svo[2]))\n",
    "                #para as sentencas sem objetos, adicionamos o verbo lematizado e o verbo como foi encontrado no texto\n",
    "                ## na lista de tuplas no_obj_verb, onde guardamos todos os verbos que em algum momento não tiveram objetos.\n",
    "                if svo[2] == None and svo[2] not in no_obj_verb:\n",
    "                    no_obj_verb.append((verb, svo[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Exibir as\tseguintes\testatísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvamos para cada verbo o numero de tuplas (sujeitos, objetos) que ele contem.\n",
    "stat_verbs = {'verbo': [], 'num_svo': []}\n",
    "for verb in lemma_verb:\n",
    "    stat_verbs['verbo'].append(verb)\n",
    "    stat_verbs['num_svo'].append(len(lemma_verb[verb]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Qual\tverbo\ttem\ta\tmaior\tlista\tde\tsujeitos\te\tobjetos ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbo</th>\n",
       "      <th>num_svo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ser</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verbo  num_svo\n",
       "58   ser      251"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbo com o maior numero de lista de sujeitos e objetos.\n",
    "df = pd.DataFrame(stat_verbs, columns=['verbo','num_svo'])\n",
    "df.sort_values(by=\"num_svo\").tail(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Há\talgum\tverbo\tsem\tobjetos?\tMostre\talguns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "[('existir', existe), ('desencadear', desencadeada), ('costumar', costumam), ('monitorados', monitorados), ('encarnar', encarnara), ('apontar', apontou), ('saber', soubessem), ('saber', sabe), ('espalhandose', espalhandose), ('Apolo', Apolo)]\n"
     ]
    }
   ],
   "source": [
    "print(len(no_obj_verb))\n",
    "print(no_obj_verb[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dada\tuma\tpergunta, no formato “O\tque/quem verbo?\" responde “O que/quem verbo\tobjeto”.\n",
    "- Exemplos\tde\tperguntas:\n",
    "Quem\tpintou\tum\tquadro?\n",
    "O\tque\tderrubou\tos\tpreços?\n",
    "- Exemplos\tde\trespostas:\n",
    "Michelangelo\tpintar\tquadros.\n",
    "Notícias\truins\tderrubar\tos\tpreços."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faça uma pergunta no formato:  “O que/quem verbo? ”\n",
      " quem tem bateria ?\n"
     ]
    }
   ],
   "source": [
    "question = input('Faça uma pergunta no formato:  “O que/quem verbo? ”\\n ')\n",
    "#recebe a pergunta normalizada na forma [sujeito:que/quem, verbo, objeto]\n",
    "ext_data = syntax_normalizer.get_SVO(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aparelhos ter bateria\n"
     ]
    }
   ],
   "source": [
    "\n",
    "verbo = ext_data[0][1].lemma_\n",
    "obj = ext_data[0][2]\n",
    "#fazemos um matching entre o objeto e o verbo e assim encontramos todas as combinações que ambos aparecem\n",
    "# e adicionamos o sujeito para cada caso.\n",
    "for tupla in lemma_verb[verbo]:\n",
    "    if tupla[1] != None and obj.text == tupla[1].text:\n",
    "        suj = tupla[0]\n",
    "        print(str(suj) + ' ' + str(verbo) + ' ' + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
